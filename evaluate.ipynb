{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abHIqQbMPVYn",
        "outputId": "858dd25e-0dc8-45ac-80da-d5902a915774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trec_eval'...\n",
            "remote: Enumerating objects: 1147, done.\u001b[K\n",
            "remote: Counting objects: 100% (296/296), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 1147 (delta 229), reused 241 (delta 190), pack-reused 851 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1147/1147), 756.14 KiB | 4.11 MiB/s, done.\n",
            "Resolving deltas: 100% (773/773), done.\n",
            "gcc -g -I.  -Wall -Wno-macro-redefined -DVERSIONID=\\\"10.0-rc2\\\"  -o trec_eval trec_eval.c formats.c meas_init.c meas_acc.c meas_avg.c meas_print_single.c meas_print_final.c gain_init.c get_qrels.c get_trec_results.c get_prefs.c get_qrels_prefs.c get_qrels_jg.c form_res_rels.c form_res_rels_jg.c form_prefs_counts.c utility_pool.c get_zscores.c convert_zscores.c measures.c  m_map.c m_P.c m_num_q.c m_num_ret.c m_num_rel.c m_num_rel_ret.c m_gm_map.c m_Rprec.c m_recip_rank.c m_bpref.c m_iprec_at_recall.c m_recall.c m_Rprec_mult.c m_utility.c m_11pt_avg.c m_ndcg.c m_ndcg_cut.c m_Rndcg.c m_ndcg_rel.c m_binG.c m_G.c m_rel_P.c m_success.c m_infap.c m_map_cut.c m_gm_bpref.c m_runid.c m_relstring.c m_set_P.c m_set_recall.c m_set_rel_P.c m_set_map.c m_set_F.c m_num_nonrel_judged_ret.c m_prefs_num_prefs_poss.c m_prefs_num_prefs_ful.c m_prefs_num_prefs_ful_ret.c m_prefs_simp.c m_prefs_pair.c m_prefs_avgjg.c m_prefs_avgjg_Rnonrel.c m_prefs_simp_ret.c m_prefs_pair_ret.c m_prefs_avgjg_ret.c m_prefs_avgjg_Rnonrel_ret.c m_prefs_simp_imp.c m_prefs_pair_imp.c m_prefs_avgjg_imp.c m_map_avgjg.c m_Rprec_mult_avgjg.c m_P_avgjg.c m_yaap.c m_rbp.c m_rbp_resid.c m_unjudged.c -lm\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/usnistgov/trec_eval.git\n",
        "!cd trec_eval && make\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load the results file skipping the first row (header)\n",
        "results_df = pd.read_csv('/content/Results.txt', sep='\\s+', header=0, names=[\"query_id\", \"Q0\", \"doc_id\", \"rank\", \"score\", \"tag\"])\n",
        "results_title_df = pd.read_csv('/content/Results_title.txt', sep='\\s+', header=0, names=[\"query_id\", \"Q0\", \"doc_id\", \"rank\", \"score\", \"tag\"])\n",
        "results_title_text_df = pd.read_csv('/content/Results_title_text.txt', sep='\\s+', header=0, names=[\"query_id\", \"Q0\", \"doc_id\", \"rank\", \"score\", \"tag\"])\n",
        "\n",
        "# convert query_id to string type\n",
        "results_df['query_id'] = results_df['query_id'].astype(str)\n",
        "results_title_df['query_id'] = results_title_df['query_id'].astype(str)\n",
        "results_title_text_df['query_id'] = results_title_text_df['query_id'].astype(str)\n",
        "\n",
        "# clean the query_id column\n",
        "results_df['query_id'] = results_df['query_id'].str.replace('Q0-', '', regex=False)\n",
        "results_title_df['query_id'] = results_title_df['query_id'].str.replace('Q0-', '', regex=False)\n",
        "results_title_text_df['query_id'] = results_title_text_df['query_id'].str.replace('Q0-', '', regex=False)\n",
        "\n",
        "# save the cleaned results file (without the header)\n",
        "results_df.to_csv('/content/cleaned_Results.txt', sep=' ', index=False, header=False)\n",
        "results_title_df.to_csv('/content/cleaned_Results_title.txt', sep=' ', index=False, header=False)\n",
        "results_title_text_df.to_csv('/content/cleaned_Results_title_text.txt', sep=' ', index=False, header=False)\n",
        "\n",
        "# run the trec_eval on the cleaned results text\n",
        "print(\"Score for Corpus text only\")\n",
        "!cd trec_eval && ./trec_eval /content/test.qrel /content/cleaned_Results.txt\n",
        "\n",
        "# run the trec_eval on the cleaned results title\n",
        "print(\"Score for Corpus title only\")\n",
        "!cd trec_eval && ./trec_eval /content/test.qrel /content/cleaned_Results_title.txt\n",
        "\n",
        "# run the trec_eval on the cleaned results title text\n",
        "print(\"Score for Corpus title and text\")\n",
        "!cd trec_eval && ./trec_eval /content/test.qrel /content/cleaned_Results_title_text.txt\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcArgCZiSIIq",
        "outputId": "f930a2e5-795c-47d7-d7f1-d52f1943b021"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for Corpus text only\n",
            "runid                 \tall\t5d7d54f3-bbcd-4a7b-ae8d-78bbf505b716\n",
            "num_q                 \tall\t300\n",
            "num_ret               \tall\t29931\n",
            "num_rel               \tall\t339\n",
            "num_rel_ret           \tall\t297\n",
            "map                   \tall\t0.4657\n",
            "gm_map                \tall\t0.0918\n",
            "Rprec                 \tall\t0.3512\n",
            "bpref                 \tall\t0.8759\n",
            "recip_rank            \tall\t0.4773\n",
            "iprec_at_recall_0.00  \tall\t0.4774\n",
            "iprec_at_recall_0.10  \tall\t0.4774\n",
            "iprec_at_recall_0.20  \tall\t0.4774\n",
            "iprec_at_recall_0.30  \tall\t0.4773\n",
            "iprec_at_recall_0.40  \tall\t0.4762\n",
            "iprec_at_recall_0.50  \tall\t0.4735\n",
            "iprec_at_recall_0.60  \tall\t0.4735\n",
            "iprec_at_recall_0.70  \tall\t0.4704\n",
            "iprec_at_recall_0.80  \tall\t0.4577\n",
            "iprec_at_recall_0.90  \tall\t0.4544\n",
            "iprec_at_recall_1.00  \tall\t0.4544\n",
            "P_5                   \tall\t0.1280\n",
            "P_10                  \tall\t0.0733\n",
            "P_15                  \tall\t0.0547\n",
            "P_20                  \tall\t0.0427\n",
            "P_30                  \tall\t0.0303\n",
            "P_100                 \tall\t0.0099\n",
            "P_200                 \tall\t0.0049\n",
            "P_500                 \tall\t0.0020\n",
            "P_1000                \tall\t0.0010\n",
            "Score for Corpus title only\n",
            "runid                 \tall\taaa1cfe0-4bd9-4fc2-abf6-98c35ab6854e\n",
            "num_q                 \tall\t300\n",
            "num_ret               \tall\t28583\n",
            "num_rel               \tall\t339\n",
            "num_rel_ret           \tall\t235\n",
            "map                   \tall\t0.3520\n",
            "gm_map                \tall\t0.0121\n",
            "Rprec                 \tall\t0.2646\n",
            "bpref                 \tall\t0.6807\n",
            "recip_rank            \tall\t0.3680\n",
            "iprec_at_recall_0.00  \tall\t0.3683\n",
            "iprec_at_recall_0.10  \tall\t0.3683\n",
            "iprec_at_recall_0.20  \tall\t0.3683\n",
            "iprec_at_recall_0.30  \tall\t0.3680\n",
            "iprec_at_recall_0.40  \tall\t0.3628\n",
            "iprec_at_recall_0.50  \tall\t0.3558\n",
            "iprec_at_recall_0.60  \tall\t0.3558\n",
            "iprec_at_recall_0.70  \tall\t0.3551\n",
            "iprec_at_recall_0.80  \tall\t0.3413\n",
            "iprec_at_recall_0.90  \tall\t0.3406\n",
            "iprec_at_recall_1.00  \tall\t0.3406\n",
            "P_5                   \tall\t0.0973\n",
            "P_10                  \tall\t0.0547\n",
            "P_15                  \tall\t0.0396\n",
            "P_20                  \tall\t0.0307\n",
            "P_30                  \tall\t0.0218\n",
            "P_100                 \tall\t0.0078\n",
            "P_200                 \tall\t0.0039\n",
            "P_500                 \tall\t0.0016\n",
            "P_1000                \tall\t0.0008\n",
            "Score for Corpus title and text\n",
            "runid                 \tall\ta06e8ec5-c2ec-443b-8cc5-142febf16054\n",
            "num_q                 \tall\t300\n",
            "num_ret               \tall\t29933\n",
            "num_rel               \tall\t339\n",
            "num_rel_ret           \tall\t304\n",
            "map                   \tall\t0.4842\n",
            "gm_map                \tall\t0.1139\n",
            "Rprec                 \tall\t0.3679\n",
            "bpref                 \tall\t0.8949\n",
            "recip_rank            \tall\t0.4957\n",
            "iprec_at_recall_0.00  \tall\t0.4959\n",
            "iprec_at_recall_0.10  \tall\t0.4959\n",
            "iprec_at_recall_0.20  \tall\t0.4959\n",
            "iprec_at_recall_0.30  \tall\t0.4958\n",
            "iprec_at_recall_0.40  \tall\t0.4936\n",
            "iprec_at_recall_0.50  \tall\t0.4915\n",
            "iprec_at_recall_0.60  \tall\t0.4915\n",
            "iprec_at_recall_0.70  \tall\t0.4894\n",
            "iprec_at_recall_0.80  \tall\t0.4771\n",
            "iprec_at_recall_0.90  \tall\t0.4733\n",
            "iprec_at_recall_1.00  \tall\t0.4733\n",
            "P_5                   \tall\t0.1347\n",
            "P_10                  \tall\t0.0773\n",
            "P_15                  \tall\t0.0556\n",
            "P_20                  \tall\t0.0430\n",
            "P_30                  \tall\t0.0306\n",
            "P_100                 \tall\t0.0101\n",
            "P_200                 \tall\t0.0051\n",
            "P_500                 \tall\t0.0020\n",
            "P_1000                \tall\t0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xHzhJuuc-Y42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11bb1f1-6157-4886-b7cb-657b67ac1098"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}