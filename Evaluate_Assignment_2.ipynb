{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rTwAVj0fmPd",
        "outputId": "d329555c-a6b0-4aa9-8a37-42a5adb05ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'trec_eval'...\n",
            "remote: Enumerating objects: 1147, done.\u001b[K\n",
            "remote: Counting objects: 100% (332/332), done.\u001b[K\n",
            "remote: Compressing objects: 100% (100/100), done.\u001b[K\n",
            "remote: Total 1147 (delta 264), reused 277 (delta 226), pack-reused 815 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1147/1147), 764.18 KiB | 2.32 MiB/s, done.\n",
            "Resolving deltas: 100% (769/769), done.\n",
            "gcc -g -I.  -Wall -Wno-macro-redefined -DVERSIONID=\\\"10.0-rc2\\\"  -o trec_eval trec_eval.c formats.c meas_init.c meas_acc.c meas_avg.c meas_print_single.c meas_print_final.c gain_init.c get_qrels.c get_trec_results.c get_prefs.c get_qrels_prefs.c get_qrels_jg.c form_res_rels.c form_res_rels_jg.c form_prefs_counts.c utility_pool.c get_zscores.c convert_zscores.c measures.c  m_map.c m_P.c m_num_q.c m_num_ret.c m_num_rel.c m_num_rel_ret.c m_gm_map.c m_Rprec.c m_recip_rank.c m_bpref.c m_iprec_at_recall.c m_recall.c m_Rprec_mult.c m_utility.c m_11pt_avg.c m_ndcg.c m_ndcg_cut.c m_Rndcg.c m_ndcg_rel.c m_binG.c m_G.c m_rel_P.c m_success.c m_infap.c m_map_cut.c m_gm_bpref.c m_runid.c m_relstring.c m_set_P.c m_set_recall.c m_set_rel_P.c m_set_map.c m_set_F.c m_num_nonrel_judged_ret.c m_prefs_num_prefs_poss.c m_prefs_num_prefs_ful.c m_prefs_num_prefs_ful_ret.c m_prefs_simp.c m_prefs_pair.c m_prefs_avgjg.c m_prefs_avgjg_Rnonrel.c m_prefs_simp_ret.c m_prefs_pair_ret.c m_prefs_avgjg_ret.c m_prefs_avgjg_Rnonrel_ret.c m_prefs_simp_imp.c m_prefs_pair_imp.c m_prefs_avgjg_imp.c m_map_avgjg.c m_Rprec_mult_avgjg.c m_P_avgjg.c m_yaap.c m_rbp.c m_rbp_resid.c m_unjudged.c -lm\n"
          ]
        }
      ],
      "source": [
        "# Clone and compile trec_eval\n",
        "!git clone https://github.com/usnistgov/trec_eval.git\n",
        "!cd trec_eval && make\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605a141e-1982-4ad2-e816-093439078790",
        "id": "jIHPZ0GOgU4v"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Title + Text\n",
            "runid                 \tall\ta06e8ec5-c2ec-443b-8cc5-142febf16054\n",
            "num_q                 \tall\t300\n",
            "num_ret               \tall\t29933\n",
            "num_rel               \tall\t339\n",
            "num_rel_ret           \tall\t304\n",
            "map                   \tall\t0.4842\n",
            "gm_map                \tall\t0.1139\n",
            "Rprec                 \tall\t0.3679\n",
            "bpref                 \tall\t0.8949\n",
            "recip_rank            \tall\t0.4957\n",
            "iprec_at_recall_0.00  \tall\t0.4959\n",
            "iprec_at_recall_0.10  \tall\t0.4959\n",
            "iprec_at_recall_0.20  \tall\t0.4959\n",
            "iprec_at_recall_0.30  \tall\t0.4958\n",
            "iprec_at_recall_0.40  \tall\t0.4936\n",
            "iprec_at_recall_0.50  \tall\t0.4915\n",
            "iprec_at_recall_0.60  \tall\t0.4915\n",
            "iprec_at_recall_0.70  \tall\t0.4894\n",
            "iprec_at_recall_0.80  \tall\t0.4771\n",
            "iprec_at_recall_0.90  \tall\t0.4733\n",
            "iprec_at_recall_1.00  \tall\t0.4733\n",
            "P_5                   \tall\t0.1347\n",
            "P_10                  \tall\t0.0773\n",
            "P_15                  \tall\t0.0556\n",
            "P_20                  \tall\t0.0430\n",
            "P_30                  \tall\t0.0306\n",
            "P_100                 \tall\t0.0101\n",
            "P_200                 \tall\t0.0051\n",
            "P_500                 \tall\t0.0020\n",
            "P_1000                \tall\t0.0010\n",
            "\n",
            "MiniLM Rerank\n",
            "runid                 \tall\tminiLM_rerank\n",
            "num_q                 \tall\t300\n",
            "num_ret               \tall\t15000\n",
            "num_rel               \tall\t339\n",
            "num_rel_ret           \tall\t286\n",
            "map                   \tall\t0.5077\n",
            "gm_map                \tall\t0.0900\n",
            "Rprec                 \tall\t0.4035\n",
            "bpref                 \tall\t0.8511\n",
            "recip_rank            \tall\t0.5177\n",
            "iprec_at_recall_0.00  \tall\t0.5194\n",
            "iprec_at_recall_0.10  \tall\t0.5194\n",
            "iprec_at_recall_0.20  \tall\t0.5194\n",
            "iprec_at_recall_0.30  \tall\t0.5192\n",
            "iprec_at_recall_0.40  \tall\t0.5192\n",
            "iprec_at_recall_0.50  \tall\t0.5142\n",
            "iprec_at_recall_0.60  \tall\t0.5142\n",
            "iprec_at_recall_0.70  \tall\t0.5133\n",
            "iprec_at_recall_0.80  \tall\t0.5041\n",
            "iprec_at_recall_0.90  \tall\t0.4946\n",
            "iprec_at_recall_1.00  \tall\t0.4946\n",
            "P_5                   \tall\t0.1433\n",
            "P_10                  \tall\t0.0823\n",
            "P_15                  \tall\t0.0596\n",
            "P_20                  \tall\t0.0460\n",
            "P_30                  \tall\t0.0316\n",
            "P_100                 \tall\t0.0095\n",
            "P_200                 \tall\t0.0048\n",
            "P_500                 \tall\t0.0019\n",
            "P_1000                \tall\t0.0010\n",
            "\n",
            "USELM Rerank\n",
            "runid                 \tall\tuseLM_rerank\n",
            "num_q                 \tall\t300\n",
            "num_ret               \tall\t29931\n",
            "num_rel               \tall\t339\n",
            "num_rel_ret           \tall\t297\n",
            "map                   \tall\t0.3338\n",
            "gm_map                \tall\t0.0502\n",
            "Rprec                 \tall\t0.2382\n",
            "bpref                 \tall\t0.8759\n",
            "recip_rank            \tall\t0.3426\n",
            "iprec_at_recall_0.00  \tall\t0.3450\n",
            "iprec_at_recall_0.10  \tall\t0.3450\n",
            "iprec_at_recall_0.20  \tall\t0.3450\n",
            "iprec_at_recall_0.30  \tall\t0.3448\n",
            "iprec_at_recall_0.40  \tall\t0.3427\n",
            "iprec_at_recall_0.50  \tall\t0.3387\n",
            "iprec_at_recall_0.60  \tall\t0.3387\n",
            "iprec_at_recall_0.70  \tall\t0.3380\n",
            "iprec_at_recall_0.80  \tall\t0.3311\n",
            "iprec_at_recall_0.90  \tall\t0.3243\n",
            "iprec_at_recall_1.00  \tall\t0.3243\n",
            "P_5                   \tall\t0.0947\n",
            "P_10                  \tall\t0.0573\n",
            "P_15                  \tall\t0.0424\n",
            "P_20                  \tall\t0.0343\n",
            "P_30                  \tall\t0.0261\n",
            "P_100                 \tall\t0.0099\n",
            "P_200                 \tall\t0.0049\n",
            "P_500                 \tall\t0.0020\n",
            "P_1000                \tall\t0.0010\n",
            "\n",
            "doc2vec Rerank\n",
            "runid                 \tall\tdoc2vec_rerank\n",
            "num_q                 \tall\t300\n",
            "num_ret               \tall\t15000\n",
            "num_rel               \tall\t339\n",
            "num_rel_ret           \tall\t286\n",
            "map                   \tall\t0.4651\n",
            "gm_map                \tall\t0.0789\n",
            "Rprec                 \tall\t0.3512\n",
            "bpref                 \tall\t0.8511\n",
            "recip_rank            \tall\t0.4770\n",
            "iprec_at_recall_0.00  \tall\t0.4770\n",
            "iprec_at_recall_0.10  \tall\t0.4770\n",
            "iprec_at_recall_0.20  \tall\t0.4770\n",
            "iprec_at_recall_0.30  \tall\t0.4768\n",
            "iprec_at_recall_0.40  \tall\t0.4757\n",
            "iprec_at_recall_0.50  \tall\t0.4730\n",
            "iprec_at_recall_0.60  \tall\t0.4730\n",
            "iprec_at_recall_0.70  \tall\t0.4699\n",
            "iprec_at_recall_0.80  \tall\t0.4571\n",
            "iprec_at_recall_0.90  \tall\t0.4538\n",
            "iprec_at_recall_1.00  \tall\t0.4538\n",
            "P_5                   \tall\t0.1280\n",
            "P_10                  \tall\t0.0733\n",
            "P_15                  \tall\t0.0547\n",
            "P_20                  \tall\t0.0427\n",
            "P_30                  \tall\t0.0303\n",
            "P_100                 \tall\t0.0095\n",
            "P_200                 \tall\t0.0048\n",
            "P_500                 \tall\t0.0019\n",
            "P_1000                \tall\t0.0010\n"
          ]
        }
      ],
      "source": [
        "# Import pandas and load your result files\n",
        "import pandas as pd\n",
        "\n",
        "# Load the result files, skipping header row\n",
        "results_title_text_df = pd.read_csv('/content/Results_title_text.txt', sep='\\s+', header=0, names=[\"query_id\", \"Q0\", \"doc_id\", \"rank\", \"score\", \"tag\"])\n",
        "\n",
        "# Clean the query_id columns\n",
        "for df in [results_title_text_df]:\n",
        "    df['query_id'] = df['query_id'].astype(str).str.replace('Q0-', '', regex=False)\n",
        "\n",
        "# Save cleaned versions without headers\n",
        "results_title_text_df.to_csv('/content/cleaned_Results_title_text.txt', sep=' ', index=False, header=False)\n",
        "\n",
        "\n",
        "# ⬇Evaluate each cleaned result file using trec_eval\n",
        "for label, cleaned_file in {\n",
        "    \"Title + Text\": \"cleaned_Results_title_text.txt\",\n",
        "    \"MiniLM Rerank\": \"cleaned_Results_miniLM.txt\",\n",
        "    \"USELM Rerank\": \"Results_useLM.txt\",\n",
        "    \"doc2vec Rerank\": \"Results_doc2vec.txt\"\n",
        "}.items():\n",
        "    print(f\"\\n{label}\")\n",
        "    !cd trec_eval && ./trec_eval /content/test.qrel /content/{cleaned_file}\n",
        "\n"
      ]
    }
  ]
}